# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}

filter {
        #the pattern for parsing nova compute logs
      # grok {
      #         match => { "message" => ["%{TIMESTAMP_ISO8601:created_at},%{TIMESTAMP_ISO8601:deleted_at},%{DATA:user_id},%{DATA:project_id},%{DATA:display_name},%{DATA:uuid},%{DATA:launched_on},%{INT:v_cpus},%{DATA:VM_state},%{INT:VM_memory_MB}"]}
      #                   add_field => {"deleted_state" => "1"}
      # }
            grok{
                match => { "message" => ["%{TIMESTAMP_ISO8601:created_at},%{TIMESTAMP_ISO8601:deleted_at},%{DATA:user_id},%{DATA:project_id},%{DATA:display_name},%{DATA:uuid},%{DATA:launched_on},%{INT:v_cpus},%{DATA:VM_state},%{INT:VM_memory_MB}"]}
            }
              ruby {
                        init => "require 'time'"
                        code => '
                                      t1=event.get("deleted_at")
                                      t2=event.get("created_at")
                                      duration = ""
                                      unless (t2.empty? || t2.nil?) && (t1.empty? || t1.nil?)
                                                duration=(Time.parse(t1).to_i-Time.parse(t2).to_i).abs
                                      end
                                      unless duration.is_a?(String)
                                                event.set("VM_duration",duration)
                                      end
                                      if(duration.is_a?(Integer))
                                                event.set("VM_valid_lifetime",1)
                                      else
                                                event.set("VM_valid_lifetime",0)
                                      end
                                      '
                  }
                  #Aggregate the total VM(s) lifetime
                aggregate {
                      task_id => "%{launched_on}"
                      code => "map['lifetime'] ||= 0; map['lifetime'] += event.get('VM_duration')"
                      push_map_as_event_on_timeout => true
                      # timeout_task_id_field => "launched_on"
                      timeout => 10 # 1 hour timeout, user activity will be considered finished one hour after the first event, even if events keep coming
                      inactivity_timeout => 10 # 2 minutes timeout, user activity will be considered finished if no new events arrive 5 minutes after the last event
                      timeout_tags => ['_aggregatetimeout']
                      # timeout_code => 'event.set('VM_total_lifetime',  event.get('lifetime') > 1)'
                      timeout_code => "event.set('VM_total_lifetime', event.get('lifetime'))"
                    }
            #          grok{
            #               match => { "message" => ["%{TIMESTAMP_ISO8601:created_at},%{DATA:deleted_at},%{DATA:user_id},%{DATA:project_id},%{DATA:display_name},%{DATA:uuid},%{DATA:launched_on},%{INT:v_cpus},%{DATA:VM_state},%{INT:VM_memory_MB}"]}
            # }
}



output {
  if "_grokparsefailure" in [tags] {
#     write events that didn't match to a file
    file { "path" => "/Users/basavyr/Library/Mobile Documents/com~apple~CloudDocs/Work/Pipeline/DevWorkspace/Github/ELK-Stack-macOS/Resources/LOGS/parse_failure.txt" }
  } 
else 
{
      elasticsearch {
    hosts => ["http://localhost:9200"]
    manage_template => false
    index => "%{[fields][log_type]}-index"
  }
	stdout{
		codec => rubydebug
		}
}
}
